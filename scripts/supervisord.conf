[supervisord]
nodaemon=true
logfile=/var/log/supervisord.log
pidfile=/tmp/supervisord.pid
childlogdir=/var/log

[unix_http_server]
file=/tmp/supervisor.sock

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

[supervisorctl]
serverurl=unix:///tmp/supervisor.sock

; ========= llama-server =========
[program:llama]
command=/usr/local/bin/start-llama.sh
autostart=true
autorestart=true
startsecs=5
startretries=999
stdout_logfile=/var/log/llama.log
stderr_logfile=/var/log/llama.err
environment=RLIMIT_AS=3221225472

; ========= FastAPI =========
[program:fastapi]
command=/bin/bash -lc 'exec /usr/local/bin/uvicorn src.api.main:app --host 0.0.0.0 --port 8000'
directory=/workspace
autostart=true
autorestart=true
startsecs=3
startretries=20
stdout_logfile=/var/log/fastapi.log
stderr_logfile=/var/log/fastapi.err

; ========= CPU Worker =========
[program:worker-cpu]
command=/bin/bash -lc 'exec python3 -m src.backend.worker'
directory=/workspace
autostart=false
autorestart=true
startsecs=3
startretries=20
stdout_logfile=/var/log/worker-cpu.log
stderr_logfile=/var/log/worker-cpu.err
environment=RLIMIT_AS=4294967296,WORKER_MODE="cpu"

; ========= GPU Worker =========
[program:worker-gpu]
command=/bin/bash -lc 'exec python3 -m src.backend.worker'
directory=/workspace
autostart=false
autorestart=true
startsecs=3
startretries=20
stdout_logfile=/var/log/worker-gpu.log
stderr_logfile=/var/log/worker-gpu.err
environment=RLIMIT_AS=4294967296,WORKER_MODE="gpu"

; ========= Next.js =========
[program:web]
command=/bin/bash -lc 'exec npm start --prefix web'
directory=/workspace
autostart=false
autorestart=true
startsecs=3
startretries=20
stdout_logfile=/var/log/web.log
stderr_logfile=/var/log/web.err
